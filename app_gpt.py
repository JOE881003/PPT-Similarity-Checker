import streamlit as st
from pptx import Presentation
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ==== æ–°å¢ï¼šOpenAI ====
from openai import OpenAI

# ---------- ä½ åŸæœ¬çš„å‡½å¼ ----------
def extract_text_from_ppt(uploaded_file) -> str:
    """å¾ä¸Šå‚³çš„ PPT æª”æ¡ˆæå–æ–‡å­—"""
    prs = Presentation(uploaded_file)
    text_list = []
    for slide in prs.slides:
        for shape in slide.shapes:
            if hasattr(shape, "text") and shape.text.strip():
                text_list.append(shape.text)
    return " ".join(text_list)

def calculate_similarity(text_main: str, text_other: str) -> float:
    """è¨ˆç®—å…©ä»½æ–‡å­—çš„ç›¸ä¼¼åº¦"""
    vectorizer = TfidfVectorizer().fit([text_main, text_other])
    vecs = vectorizer.transform([text_main, text_other])
    return cosine_similarity(vecs[0], vecs[1])[0][0]

# ---------- æ–°å¢ï¼šæ‘˜è¦å·¥å…· ----------
def chunk_text(s: str, max_chars: int = 4000):
    """ç²—ç•¥ä¾å­—å…ƒé•·åº¦åˆ†æ®µï¼ˆé¿å…ä¸€æ¬¡ä¸Ÿå¤ªé•·ï¼‰"""
    s = s.replace("\x00", " ")  # æ¸…ç†æ€ªå­—å…ƒ
    return [s[i:i+max_chars] for i in range(0, len(s), max_chars)] or ["(ç©ºç™½)"]

def summarize_long_text(text: str, client: OpenAI, model: str = "gpt-4o-mini") -> str:
    """å…ˆå°æ¯æ®µåšå±€éƒ¨æ‘˜è¦ï¼Œå†åšå…¨å±€æ•´åˆæ‘˜è¦"""
    parts = chunk_text(text, max_chars=4000)

    partial_summaries = []
    for idx, part in enumerate(parts, 1):
        prompt = (
            "ä½ æ˜¯ä¸€ä½ç°¡å ±é¡§å•ï¼Œè«‹ç”¨ç¹é«”ä¸­æ–‡å°‡ä¸‹åˆ—å…§å®¹é‡é»å¼æ‘˜è¦æˆ 3-6 é»ï¼Œ"
            "æ¯é»ä¸€å¥è©±ã€é¿å…é‡è¤‡èˆ‡å†—è©ï¼Œä¸¦åœ¨æœ€å¾Œçµ¦ 3-6 å€‹é—œéµå­—ï¼ˆ#æ¨™ç±¤ï¼‰ã€‚\n\n"
            f"[åˆ†æ®µ {idx}/{len(parts)} å…§å®¹]\n{part}"
        )
        resp = client.responses.create(model=model, input=prompt)
        partial_summaries.append(resp.output_text.strip())

    # å…¨å±€æ•´åˆ
    combine_prompt = (
        "ä»¥ä¸‹æ˜¯å¤šæ®µçš„å±€éƒ¨æ‘˜è¦ï¼Œè«‹èåˆæˆä¸€ä»½ã€æœ€çµ‚ç°¡å ±æ‘˜è¦ã€ï¼š\n"
        "1) å…ˆçµ¦ä¸€æ®µ 2-3 å¥çš„ç¸½è¦½ï¼ˆTL;DRï¼‰ã€‚\n"
        "2) æ¥è‘—åˆ— 5-8 é»æ¢åˆ—é‡é»ï¼ˆæ¯é» â‰¤ 25 å­—ï¼‰ã€‚\n"
        "3) æœ€å¾Œåˆ—å‡º 5-10 å€‹é—œéµå­—ï¼ˆ#æ¨™ç±¤ï¼‰ã€‚\n\n"
        "=== å±€éƒ¨æ‘˜è¦é–‹å§‹ ===\n" + "\n\n---\n\n".join(partial_summaries)
    )
    final_resp = client.responses.create(model=model, input=combine_prompt)
    return final_resp.output_text.strip()

# ---------- Streamlit UI ----------
st.title("PPT ç›¸ä¼¼åº¦æ¯”å°å·¥å…· + GPT æ‘˜è¦")
st.write("ä¸Šå‚³å…©ä»½ **PPTX** ç°¡å ±ï¼Œç³»çµ±æœƒè¨ˆç®—æ–‡å­—ç›¸ä¼¼åº¦ï¼Œä¸¦å¯ç”¨ **GPT** ç”¢ç”Ÿæ‘˜è¦ã€‚")

# å»ºè­°ç”¨ Secretsï¼›é€™è£¡æä¾›è‡¨æ™‚è¼¸å…¥æ¬„ä½ä»¥ä¾¿æ¸¬è©¦
#api_key = st.text_input("OpenAI API Keyï¼ˆä»¥ sk- é–‹é ­ï¼‰", type="password", help="æ­£å¼ä¸Šç·šè«‹æ”¹ç”¨ st.secrets ä¿å­˜")
api_key = st.secrets["openai"]["api_key"]
model = st.selectbox("æ‘˜è¦æ¨¡å‹", ["gpt-4o-mini", "gpt-4o"], index=0)

col1, col2 = st.columns(2)
with col1:
    ppt1 = st.file_uploader("ä¸Šå‚³ç¬¬ä¸€ä»½ PPT", type=["pptx"], key="ppt1")
with col2:
    ppt2 = st.file_uploader("ä¸Šå‚³ç¬¬äºŒä»½ PPT", type=["pptx"], key="ppt2")

if ppt1 and ppt2:
    with st.spinner("æ­£åœ¨åˆ†æç°¡å ±å…§å®¹..."):
        text1 = extract_text_from_ppt(ppt1)
        text2 = extract_text_from_ppt(ppt2)
        score = calculate_similarity(text1, text2)

    st.success(f"å…©ä»½ç°¡å ±çš„ç›¸ä¼¼åº¦ç‚ºï¼š **{score:.4f}**")

    st.subheader("æ–‡å­—æ‘˜è¦ï¼ˆæˆªæ–·å±•ç¤ºï¼‰")
    st.write("**ç°¡å ± 1 éƒ¨åˆ†å…§å®¹ï¼š**", (text1[:500] + "...") if len(text1) > 500 else text1)
    st.write("**ç°¡å ± 2 éƒ¨åˆ†å…§å®¹ï¼š**", (text2[:500] + "...") if len(text2) > 500 else text2)

    # ---------- æ–°å¢ï¼šç”¨ GPT ç”¢ç”Ÿæ‘˜è¦ ----------
    if api_key:
        if st.button("ç”¢ç”Ÿå…©ä»½ PPT çš„ GPT æ‘˜è¦"):
            try:
                client = OpenAI(api_key=api_key)
                with st.spinner("GPT æ­£åœ¨ç”¢ç”Ÿæ‘˜è¦ï¼ˆç°¡å ± 1ï¼‰â€¦"):
                    summary1 = summarize_long_text(text1, client, model=model)
                with st.spinner("GPT æ­£åœ¨ç”¢ç”Ÿæ‘˜è¦ï¼ˆç°¡å ± 2ï¼‰â€¦"):
                    summary2 = summarize_long_text(text2, client, model=model)

                st.subheader("GPT æ‘˜è¦ï¼šç°¡å ± 1")
                st.markdown(summary1)

                st.subheader("GPT æ‘˜è¦ï¼šç°¡å ± 2")
                st.markdown(summary2)

                # é¡å¤–ï¼šæ¯”å°å·®ç•°é‡é»ï¼ˆå¯é¸ï¼‰
                with st.spinner("GPT æ­£åœ¨æ¯”å°å…©ä»½æ‘˜è¦å·®ç•°â€¦"):
                    diff_prompt = (
                        "è«‹ä»¥ç¹é«”ä¸­æ–‡æ¯”è¼ƒå…©ä»½æ‘˜è¦ä¹‹å·®ç•°ï¼š\n"
                        "1) å…±åŒä¸»é¡Œï¼ˆè¦é»åˆ—å‡ºï¼‰\n"
                        "2) å„è‡ªç¨ç‰¹é‡é»ï¼ˆå·¦/å³å„åˆ— 3-6 é»ï¼‰\n"
                        "3) å»ºè­°ï¼šå¦‚æœè¦åˆä½µæˆä¸€ä»½ç°¡å ±ï¼Œå»ºè­°çš„çµæ§‹ç¶±è¦ï¼ˆ3-5 ç¯€ï¼‰\n\n"
                        f"[æ‘˜è¦A]\n{summary1}\n\n[æ‘˜è¦B]\n{summary2}"
                    )
                    diff = client.responses.create(model=model, input=diff_prompt).output_text
                st.subheader("ğŸ” æ‘˜è¦å·®ç•°èˆ‡åˆä½µå»ºè­°")
                st.markdown(diff)

            except Exception as e:
                st.error(f"å‘¼å« OpenAI å¤±æ•—ï¼š{e}")
    else:
        st.info("è‹¥è¦ç”¢ç”Ÿ GPT æ‘˜è¦ï¼Œè«‹å…ˆè¼¸å…¥ OpenAI API Keyã€‚")
else:
    st.info("è«‹å…ˆä¸Šå‚³å…©ä»½ PPTX æª”æ¡ˆ")
